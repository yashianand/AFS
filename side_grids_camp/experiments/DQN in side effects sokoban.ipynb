{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WBCViekXF5oK"},"source":["Code for DQN taken from: https://github.com/dennybritz/reinforcement-learning/tree/master/DQN and adjusted to gridworlds (I did the exercise! - Karoru)."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1794,"status":"ok","timestamp":1523632432715,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"eVwkHS-3kdcu","outputId":"a28cc850-c14e-4806-b3c0-87888b5a607b"},"outputs":[{"name":"stdout","output_type":"stream","text":["AUTHORS              README.md            \u001b[34mpycolab\u001b[m\u001b[m\n","CONTRIBUTING.md      \u001b[34mai_safety_gridworlds\u001b[m\u001b[m \u001b[34mside_grids_camp\u001b[m\u001b[m\n","LICENSE              hello.txt\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","id":"RTI-aFJkF5oL"},"outputs":[],"source":["from __future__ import print_function\n","import itertools\n","import numpy as np\n","import os\n","import random\n","import sys\n","# import tensorflow as tf\n","from collections import deque, namedtuple\n","from matplotlib import pyplot as plt\n","import datetime\n","\n","\n","if \"ai-safety-gridworlds/\" not in sys.path:\n","  sys.path.append(\"ai-safety-gridworlds/\")\n","\n","from ai_safety_gridworlds.environments.side_effects_sokoban import SideEffectsSokobanEnvironment as sokoban_game\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","executionInfo":{"elapsed":548,"status":"ok","timestamp":1523632793792,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"pL5psryxF5oO","outputId":"d70118e0-76b6-4b56-dc02-8c71784a3afb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Worlds limits: (6, 6)\n","RGB format: (3, 6, 6)\n"]}],"source":["BATCH_SIZE = 16\n","\n","env = sokoban_game(level=0)\n","VALID_ACTIONS = list(range(env.action_spec().maximum + 1))\n","WORLD_LIMS = env.observation_spec()['board'].shape\n","WX, WY = WORLD_LIMS\n","FRAMES_STATE = 2\n","print(\"Worlds limits: {}\".format(WORLD_LIMS))\n","print(\"RGB format: {}\".format(env.observation_spec()['RGB'].shape))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":683},"colab_type":"code","executionInfo":{"elapsed":577,"status":"ok","timestamp":1523632794436,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"YAthUVK8F5oU","outputId":"fe0d9990-50a6-4b03-e5b8-731a2ca17425"},"outputs":[{"name":"stdout","output_type":"stream","text":["Step type: first True, mid False, last False\n","Reward None, discount None\n","Observation type: <class 'dict'>\n","Let's act..\n","Step type: first False, mid True, last False\n","Reward -1, discount 1.0\n","Observation type: <class 'dict'>\n","RGB image dims: (3, 6, 6)\n","Plot from rgb:\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Plot board:\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["## Some tests:\n","\n","# TimeStep inherits from:\n","#   collections.namedtuple('TimeStep',\n","#                          ['step_type', 'reward', 'discount', 'observation'])\n","#\n","# it adds following methods:\n","#  time_step = env.reset()\n","#  time_step.first()\n","#  time_step.mid()\n","#  time_step.last()\n","\n","time_step = env.reset()\n","print(\"Step type: first {}, mid {}, last {}\".format(time_step.first(), time_step.mid(), time_step.last()))\n","print(\"Reward {}, discount {}\".format(time_step.reward, time_step.discount))\n","print(\"Observation type: {}\".format(type(time_step.observation)))\n","\n","print(\"Let's act..\")\n","time_step = env.step(2)\n","print(\"Step type: first {}, mid {}, last {}\".format(time_step.first(), time_step.mid(), time_step.last()))\n","print(\"Reward {}, discount {}\".format(time_step.reward, time_step.discount))\n","print(\"Observation type: {}\".format(type(time_step.observation)))\n","\n","print(\"RGB image dims: {}\".format(time_step.observation['RGB'].shape))\n","print(\"Plot from rgb:\")\n","frame = np.moveaxis(time_step.observation['RGB'],0,-1)\n","plt.figure()\n","plt.imshow(frame)\n","plt.axis('off')\n","plt.show()\n","\n","print(\"Plot board:\")\n","plt.figure()\n","plt.imshow(time_step.observation['board'])\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","executionInfo":{"elapsed":758,"status":"ok","timestamp":1523634141211,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"A8GRCM5nF5oX","outputId":"6834b332-e922-4346-ba78-6d9f9673f5ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Start training side effects sokoban.\n","Return: 19, elasped: 0:00:00.009488.\n","Performance: 19.0.\n","Training finished.\n"]}],"source":["## Sokoban env usage example:\n","\n","print(\"Start training side effects sokoban.\")\n","env = sokoban_game(level=0)\n","\n","start_time = datetime.datetime.now()\n","ret = 0\n","\n","actions = env.action_spec().maximum + 1\n","time_step = env.reset()  # for the description of timestep see ai_safety_gridworlds.environments.shared.rl.environment\n","while not time_step.last():\n","    # action = supa_safe_agent.act(time_step.observation)  # implement this\n","    action = np.random.choice(actions)\n","    time_step = env.step(action)\n","    # supa_safe_agent.learn(time_step, action)  # implement this\n","    ret += time_step.reward\n","\n","elapsed = datetime.datetime.now() - start_time\n","print(\"Return: {}, elasped: {}.\".format(ret, elapsed))\n","print(\"Performance: {}.\".format(env.get_last_performance()))\n","print(\"Training finished.\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":562,"status":"ok","timestamp":1523634147552,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"BWujMOwpF5ob","outputId":"cbf8f530-57ab-4aba-a879-71682a8beff0"},"outputs":[{"data":{"text/plain":["ArraySpec(shape=(3, 6, 6), dtype=dtype('uint8'), name='RGB')"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["env.observation_spec()['RGB']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","id":"6qhloQROF5oe"},"outputs":[],"source":["class StateProcessor():\n","    \"\"\"\n","    Processes a raw Atari images. Resizes it and converts it to grayscale.\n","    \"\"\"\n","    def __init__(self):\n","        # Build the Tensorflow graph\n","        with tf.variable_scope(\"state_processor\"):\n","            self.input_state = tf.placeholder(shape=[WX, WY, 3], dtype=tf.uint8)\n","            self.output = tf.image.rgb_to_grayscale(self.input_state)\n","            self.output = tf.squeeze(self.output)\n","\n","    def process(self, sess, state):\n","        \"\"\"\n","        Args:\n","            sess: A Tensorflow session object\n","            state: A [WX, WY, 3] gridworld RGB State\n","\n","        Returns:\n","            A processed [WX, WY] state representing grayscale values.\n","        \"\"\"\n","        return sess.run(self.output, { self.input_state: state })"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","id":"DWHsmfiGF5og"},"outputs":[],"source":["class Estimator():\n","    \"\"\"Q-Value Estimator neural network.\n","\n","    This network is used for both the Q-Network and the Target Network.\n","    \"\"\"\n","\n","    def __init__(self, scope=\"estimator\", summaries_dir=None):\n","        self.scope = scope\n","        # Writes Tensorboard summaries to disk\n","        self.summary_writer = None\n","        with tf.variable_scope(scope):\n","            # Build the graph\n","            self._build_model()\n","            if summaries_dir:\n","                summary_dir = os.path.join(summaries_dir, \"summaries_{}\".format(scope))\n","                if not os.path.exists(summary_dir):\n","                    os.makedirs(summary_dir)\n","                self.summary_writer = tf.summary.FileWriter(summary_dir)\n","\n","    def _build_model(self):\n","        \"\"\"\n","        Builds the Tensorflow graph.\n","        \"\"\"\n","\n","        # Placeholders for our input\n","        # Our input are FRAMES_STATE RGB frames of shape of the gridworld\n","        self.X_pl = tf.placeholder(shape=[None, WX, WY, FRAMES_STATE], dtype=tf.uint8, name=\"X\")\n","        # The TD target value\n","        self.y_pl = tf.placeholder(shape=[None], dtype=tf.float32, name=\"y\")\n","        # Integer id of which action was selected\n","        self.actions_pl = tf.placeholder(shape=[None], dtype=tf.int32, name=\"actions\")\n","\n","        X = tf.to_float(self.X_pl) / 255.0\n","        batch_size = tf.shape(self.X_pl)[0]\n","\n","        # Three convolutional layers\n","        # tf.contrib.layers.conv2d(input, num_outputs, kernel_size, stride)\n","        conv1 = tf.contrib.layers.conv2d(X, 64, 2, 1, activation_fn=tf.nn.relu)\n","        # try with padding = 'VALID'\n","        # pool1 = tf.contrib.layers.max_pool2d(conv1, 2)\n","        # conv2 = tf.contrib.layers.conv2d(pool1, 32, WX, 1, activation_fn=tf.nn.relu)\n","        \n","        # Fully connected layers\n","        flattened = tf.contrib.layers.flatten(conv1)\n","        fc1 = tf.contrib.layers.fully_connected(flattened, 64)\n","        self.predictions = tf.contrib.layers.fully_connected(fc1, len(VALID_ACTIONS))\n","\n","        # Get the predictions for the chosen actions only\n","        gather_indices = tf.range(batch_size) * tf.shape(self.predictions)[1] + self.actions_pl\n","        self.action_predictions = tf.gather(tf.reshape(self.predictions, [-1]), gather_indices)\n","\n","        # Calcualte the loss\n","        self.losses = tf.squared_difference(self.y_pl, self.action_predictions)\n","        self.loss = tf.reduce_mean(self.losses)\n","\n","        # Optimizer Parameters from original paper\n","        self.optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6)\n","        self.train_op = self.optimizer.minimize(self.loss, global_step=tf.train.get_global_step())\n","\n","        # Summaries for Tensorboard\n","        self.summaries = tf.summary.merge([\n","            tf.summary.scalar(\"loss\", self.loss),\n","            tf.summary.histogram(\"loss_hist\", self.losses),\n","            tf.summary.histogram(\"q_values_hist\", self.predictions),\n","            tf.summary.scalar(\"max_q_value\", tf.reduce_max(self.predictions))\n","        ])\n","\n","    def predict(self, sess, s):\n","        \"\"\"\n","        Predicts action values.\n","\n","        Args:\n","          sess: Tensorflow session\n","          s: State input of shape [batch_size, FRAMES_STATE, 160, 160, 3]\n","\n","        Returns:\n","          Tensor of shape [batch_size, NUM_VALID_ACTIONS] containing the estimated \n","          action values.\n","        \"\"\"\n","        return sess.run(self.predictions, { self.X_pl: s })\n","\n","    def update(self, sess, s, a, y):\n","        \"\"\"\n","        Updates the estimator towards the given targets.\n","\n","        Args:\n","          sess: Tensorflow session object\n","          s: State input of shape [batch_size, FRAMES_STATE, 160, 160, 3]\n","          a: Chosen actions of shape [batch_size]\n","          y: Targets of shape [batch_size]\n","\n","        Returns:\n","          The calculated loss on the batch.\n","        \"\"\"\n","        feed_dict = { self.X_pl: s, self.y_pl: y, self.actions_pl: a }\n","        summaries, global_step, _, loss = sess.run(\n","            [self.summaries, tf.train.get_global_step(), self.train_op, self.loss],\n","            feed_dict)\n","        if self.summary_writer:\n","            self.summary_writer.add_summary(summaries, global_step)\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":724},"colab_type":"code","executionInfo":{"elapsed":946,"status":"ok","timestamp":1523634157964,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"r95hxXA1F5oj","outputId":"4a112f37-3470-44a3-d7f8-39fd2178d0e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sokoban in grey-scale:\n","[[152 152 152 152 152 152]\n"," [152 219 134 152 152 152]\n"," [152 219  78 219 219 152]\n"," [152 152 219 219 219 152]\n"," [152 152 152 219 129 152]\n"," [152 152 152 152 152 152]]\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPQAAAD4CAYAAADb7cuFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA2lJREFUeJzt2LGNG0EQRUFR2EToMqdzmcNGMEEw2JFNUMYZJFp6V2WOsfjOQwN72Xv/Ahp+Tw8A3kfQECJoCBE0hAgaQo53f3Ct5bc5fNh5npe/vbvQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSEHNMDPu08z+kJL+73+/SEJ9frdXoCb+JCQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIOaYH/ESPx2N6wpO99/SEf95aa3rCt7jQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSEHNMDPm2tNT3hxd57egJRLjSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSHH9ICfaK01PeHJeZ7TE558fX1NT3hxu92mJ3yLCw0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIeSYHsC8tdb0hCe32216wn/LhYYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIeSy957eALyJCw0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSE/AExVSCSoLsl5gAAAABJRU5ErkJggg==","text/plain":["<matplotlib.figure.Figure at 0x7f3375c83610>"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[[0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]\n"," [0.09704053 0.         0.2624015  0.17086829]]\n","[0.2624015 0.2624015 0.2624015 0.2624015 0.2624015 0.2624015 0.2624015\n"," 0.2624015 0.2624015 0.2624015 0.2624015 0.2624015 0.2624015 0.2624015\n"," 0.2624015 0.2624015]\n","57.331123\n"]}],"source":["#\n","# Test preprocessing and estimator\n","#\n","\n","tf.reset_default_graph()\n","global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n","\n","e = Estimator(scope=\"test\")\n","sp = StateProcessor()\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    \n","    # Example observation batch\n","    time_step = env.reset()\n","    \n","    frame = np.moveaxis(time_step.observation['RGB'], 0, -1)\n","    observation_p = sp.process(sess, frame)\n","\n","    print(\"Sokoban in grey-scale:\")\n","    print(observation_p)\n","    \n","    plt.figure()\n","    plt.imshow(observation_p/255.0, cmap='gray')\n","    plt.axis('off')\n","    plt.show()\n","    \n","    observation = np.stack([observation_p] * FRAMES_STATE, axis=2)\n","    observations = np.array([observation] * BATCH_SIZE)\n","    \n","    # Test Prediction\n","    pred = e.predict(sess, observations)\n","    print(pred)\n","    print(pred.max(axis=1))\n","\n","    # Test training step\n","    y = np.array([10.0, 4.0] * (BATCH_SIZE/2))\n","    a = np.array([1, 3] * (BATCH_SIZE/2))\n","    print(e.update(sess, observations, a, y))\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Awpit0ZSF5on"},"source":["# Let's train some agents! :D"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","id":"MrmW7NiUF5oo"},"outputs":[],"source":["def copy_model_parameters(sess, estimator1, estimator2):\n","    \"\"\"\n","    Copies the model parameters of one estimator to another.\n","\n","    Args:\n","      sess: Tensorflow session instance\n","      estimator1: Estimator to copy the paramters from\n","      estimator2: Estimator to copy the parameters to\n","    \"\"\"\n","    e1_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator1.scope)]\n","    e1_params = sorted(e1_params, key=lambda v: v.name)\n","    e2_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator2.scope)]\n","    e2_params = sorted(e2_params, key=lambda v: v.name)\n","\n","    update_ops = []\n","    for e1_v, e2_v in zip(e1_params, e2_params):\n","        op = e2_v.assign(e1_v)\n","        update_ops.append(op)\n","\n","    sess.run(update_ops)\n","\n","\n","def make_epsilon_greedy_policy(estimator, nA):\n","    \"\"\"\n","    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n","\n","    Args:\n","        estimator: An estimator that returns q values for a given state\n","        nA: Number of actions in the environment.\n","\n","    Returns:\n","        A function that takes the (sess, observation, epsilon) as an argument and returns\n","        the probabilities for each action in the form of a numpy array of length nA.\n","\n","    \"\"\"\n","    def policy_fn(sess, observation, epsilon):\n","        A = np.ones(nA, dtype=float) * epsilon / nA\n","        q_values = estimator.predict(sess, np.expand_dims(observation, 0))[0]\n","        best_action = np.argmax(q_values)\n","        A[best_action] += (1.0 - epsilon)\n","        return A\n","    return policy_fn\n","\n","EpisodeStats = namedtuple(\"EpisodeStats\", [\"episode_lengths\", \"episode_rewards\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","id":"E0UtSe5CF5oq"},"outputs":[],"source":["def deep_q_learning(sess,\n","                    env,\n","                    q_estimator,\n","                    target_estimator,\n","                    state_processor,\n","                    num_episodes,\n","                    experiment_dir,\n","                    replay_memory_size=50000,\n","                    replay_memory_init_size=5000,\n","                    update_target_estimator_every=1000,\n","                    discount_factor=0.99,\n","                    epsilon_start=1.0,\n","                    epsilon_end=0.1,\n","                    epsilon_decay_steps=50000,\n","                    batch_size=BATCH_SIZE,\n","                    restore=True):\n","    \"\"\"\n","    Q-Learning algorithm for off-policy TD control using Function Approximation.\n","    Finds the optimal greedy policy while following an epsilon-greedy policy.\n","\n","    Args:\n","        sess: Tensorflow Session object\n","        env: OpenAI environment\n","        q_estimator: Estimator object used for the q values\n","        target_estimator: Estimator object used for the targets\n","        state_processor: A StateProcessor object\n","        num_episodes: Number of episodes to run for\n","        experiment_dir: Directory to save Tensorflow summaries in\n","        replay_memory_size: Size of the replay memory\n","        replay_memory_init_size: Number of random experiences to sampel when initializing \n","          the reply memory.\n","        update_target_estimator_every: Copy parameters from the Q estimator to the \n","          target estimator every N steps\n","        discount_factor: Gamma discount factor\n","        epsilon_start: Chance to sample a random action when taking an action.\n","          Epsilon is decayed over time and this is the start value\n","        epsilon_end: The final minimum value of epsilon after decaying is done\n","        epsilon_decay_steps: Number of steps to decay epsilon over\n","        batch_size: Size of batches to sample from the replay memory\n","\n","    Returns:\n","        A generator\n","        NOT ~ An EpisodeStats object with two numpy arrays for episode_lengths and episode_rewards.\n","    \"\"\"\n","\n","    Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n","\n","    # The replay memory\n","    replay_memory = []\n","\n","    # Keeps track of useful statistics\n","    stats = EpisodeStats(episode_lengths=np.zeros(num_episodes),\n","                         episode_rewards=np.zeros(num_episodes))\n","\n","    # Create directories for checkpoints and summaries\n","    checkpoint_dir = os.path.join(experiment_dir, \"checkpoints\")\n","    checkpoint_path = os.path.join(checkpoint_dir, \"model\")\n","#     monitor_path = os.path.join(experiment_dir, \"monitor\")\n","\n","    if not os.path.exists(checkpoint_dir):\n","        os.makedirs(checkpoint_dir)\n","#     if not os.path.exists(monitor_path):\n","#         os.makedirs(monitor_path)\n","\n","    saver = tf.train.Saver()\n","    # Load a previous checkpoint if we find one\n","    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n","    if latest_checkpoint and restore:\n","        print(\"Loading model checkpoint {}...\\n\".format(latest_checkpoint))\n","        saver.restore(sess, latest_checkpoint)\n","    \n","    # Get the current time step\n","    total_t = sess.run(tf.train.get_global_step())\n","\n","    # The epsilon decay schedule\n","    epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_steps)\n","\n","    # The policy we're following\n","    policy = make_epsilon_greedy_policy(q_estimator, len(VALID_ACTIONS))\n","\n","    # DONE Populate the replay memory with initial experience\n","    print(\"Populating replay memory...\")\n","    time_step = env.reset()\n","    frame = np.moveaxis(time_step.observation['RGB'], 0, -1)\n","    state = state_processor.process(sess, frame)\n","    state = np.stack([state] * FRAMES_STATE, axis=2)\n","    for i in range(replay_memory_init_size):\n","        probs = policy(sess, state, 0.9)  # you want some very random experience to populate the replay memory\n","        action = np.random.choice(VALID_ACTIONS, p=probs)\n","\n","        time_step = env.step(action)\n","        frame = np.moveaxis(time_step.observation['RGB'], 0, -1)\n","        next_state = state_processor.process(sess, frame)\n","        next_state = np.stack([state[:,:,FRAMES_STATE - 1], next_state], axis=2)\n","        done = time_step.last()\n","        \n","        replay_memory.append(Transition(state, action, time_step.reward, next_state, done))\n","        if done:\n","            time_step = env.reset()\n","            frame = np.moveaxis(time_step.observation['RGB'], 0, -1)\n","            state = state_processor.process(sess, frame)\n","            state = np.stack([state] * FRAMES_STATE, axis=2)\n","            break\n","        else:\n","            state = next_state\n","            \n","    for i_episode in range(num_episodes):\n","\n","        # Save the current checkpoint\n","        saver.save(tf.get_default_session(), checkpoint_path)\n","\n","        # Reset the environment\n","        time_step = env.reset()\n","        frame = np.moveaxis(time_step.observation['RGB'], 0, -1)\n","        state = state_processor.process(sess, frame)\n","        state = np.stack([state] * FRAMES_STATE, axis=2)\n","        loss = None\n","\n","        # One step in the environment\n","        for t in itertools.count():\n","\n","            # Epsilon for this time step\n","            epsilon = epsilons[min(total_t, epsilon_decay_steps-1)]\n","\n","            # Add epsilon to Tensorboard\n","            episode_summary = tf.Summary()\n","            episode_summary.value.add(simple_value=epsilon, tag=\"epsilon\")\n","            q_estimator.summary_writer.add_summary(episode_summary, total_t)\n","\n","            # DONE: Maybe update the target estimator\n","            if total_t % update_target_estimator_every == 0:\n","                copy_model_parameters(sess, q_estimator, target_estimator)\n","\n","            # Print out which step we're on, useful for debugging.\n","            print(\"\\rStep {} ({}) @ Episode {}/{}, loss: {}\".format(\n","                    t, total_t, i_episode + 1, num_episodes, loss), end=\"\")\n","            sys.stdout.flush()\n","\n","            # Take a step in the environment\n","            # DONE: Implement!\n","            probs = policy(sess, state, epsilon)\n","            action = np.random.choice(VALID_ACTIONS, p=probs)\n","\n","            time_step = env.step(action)\n","            frame = np.moveaxis(time_step.observation['RGB'], 0, -1)\n","            next_state = state_processor.process(sess, frame)\n","            next_state = np.stack([state[:,:,FRAMES_STATE - 1], next_state], axis=2)\n","            done = time_step.last()\n","            \n","            # If our replay memory is full, pop the first element\n","            if len(replay_memory) == replay_memory_size:\n","                replay_memory.pop(0)\n","\n","            # DONE: Save transition to replay memory\n","            replay_memory.append(Transition(state, action, time_step.reward, next_state, done))\n","            \n","\n","            # Update statistics\n","            stats.episode_rewards[i_episode] += time_step.reward\n","            stats.episode_lengths[i_episode] = t\n","\n","            # DONE: Sample a minibatch from the replay memory\n","            sample = np.random.choice(len(replay_memory), batch_size)\n","            sample = [replay_memory[i] for i in sample]\n","            \n","            sts, a, r, n_sts, d = tuple(map(np.array, zip(*sample)))\n","            \n","#             sts = np.array([replay_memory[i].state for i in sample])\n","#             n_sts = np.array([replay_memory[i].next_state for i in sample])\n","#             a = np.array([replay_memory[i].action for i in sample])\n","#             r = np.array([replay_memory[i].reward for i in sample])\n","#             d = np.array([replay_memory[i].done for i in sample])\n","            \n","            # DONE: Calculate q values and targets\n","            qs = target_estimator.predict(sess, n_sts).max(axis=1)\n","            qs[d] = 0\n","            targets = r + discount_factor * qs\n","            \n","            # DONE: Perform gradient descent update\n","            loss = q_estimator.update(sess, sts, a, targets)\n","\n","            if done:\n","                break\n","\n","            state = next_state\n","            total_t += 1\n","\n","        # Add summaries to tensorboard\n","        episode_summary = tf.Summary()\n","        episode_summary.value.add(simple_value=stats.episode_rewards[i_episode], node_name=\"episode_reward\", tag=\"episode_reward\")\n","        episode_summary.value.add(simple_value=stats.episode_lengths[i_episode], node_name=\"episode_length\", tag=\"episode_length\")\n","        q_estimator.summary_writer.add_summary(episode_summary, total_t)\n","        q_estimator.summary_writer.flush()\n","\n","        yield total_t, EpisodeStats(\n","            episode_lengths=stats.episode_lengths[:i_episode+1],\n","            episode_rewards=stats.episode_rewards[:i_episode+1])\n","\n","    # env.close()\n","    return  # stats"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":8551},"colab_type":"code","executionInfo":{"elapsed":1630391,"status":"ok","timestamp":1523636813692,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"3SqLjjpTF5os","outputId":"59e2c848-aafe-4b78-da81-d2a55aed6749"},"outputs":[{"name":"stdout","output_type":"stream","text":["Populating replay memory...\n","Step 34 (980) @ Episode 20/5000, loss: 3.40192985535\n","Episode Reward: 15.0\n","Step 38 (1109) @ Episode 25/5000, loss: 120.376846313"]},{"name":"stdout","output_type":"stream","text":["Step 66 (1917) @ Episode 40/5000, loss: 128.841812134\n","Episode Reward: -17.0\n","Step 15 (2348) @ Episode 50/5000, loss: 43.1173057556"]},{"name":"stdout","output_type":"stream","text":["Step 80 (2932) @ Episode 60/5000, loss: 51.9724884033\n","Episode Reward: -31.0\n","Step 25 (3449) @ Episode 78/5000, loss: 56.6365661621"]},{"name":"stdout","output_type":"stream","text":["Step 5 (3537) @ Episode 80/5000, loss: 14.5621175766\n","Episode Reward: 44.0\n","Step 62 (4276) @ Episode 93/5000, loss: 51.1176528931"]},{"name":"stdout","output_type":"stream","text":["Step 49 (4723) @ Episode 100/5000, loss: 80.6446762085\n","Episode Reward: 0.0\n","Step 80 (5300) @ Episode 114/5000, loss: 47.4291381836"]},{"name":"stdout","output_type":"stream","text":["Step 13 (5483) @ Episode 120/5000, loss: 83.4890518188\n","Episode Reward: 36.0\n","Step 19 (6160) @ Episode 137/5000, loss: 123.781486511"]},{"name":"stdout","output_type":"stream","text":["Step 38 (6307) @ Episode 140/5000, loss: 90.0093383789\n","Episode Reward: 11.0\n","Step 74 (6999) @ Episode 158/5000, loss: 140.710235596"]},{"name":"stdout","output_type":"stream","text":["Step 15 (7050) @ Episode 160/5000, loss: 190.074066162\n","Episode Reward: 34.0\n","Step 19 (7699) @ Episode 180/5000, loss: 322.496368408\n","Episode Reward: 30.0\n","Step 20 (7746) @ Episode 184/5000, loss: 332.869903564"]},{"name":"stdout","output_type":"stream","text":["Step 27 (8120) @ Episode 200/5000, loss: 771.70526123\n","Episode Reward: 22.0\n","Step 33 (8719) @ Episode 218/5000, loss: 347.677734375"]},{"name":"stdout","output_type":"stream","text":["Step 10 (8779) @ Episode 220/5000, loss: 262.750457764\n","Episode Reward: 39.0\n","Step 36 (9313) @ Episode 240/5000, loss: 369.75201416\n","Episode Reward: 13.0\n","Step 23 (9429) @ Episode 245/5000, loss: 115.053382874"]},{"name":"stdout","output_type":"stream","text":["Step 4 (9782) @ Episode 260/5000, loss: 591.985107422\n","Episode Reward: 45.0\n","Step 6 (10301) @ Episode 280/5000, loss: 479.51348877\n","Episode Reward: 43.0\n","Step 13 (10350) @ Episode 284/5000, loss: 219.486282349"]},{"name":"stdout","output_type":"stream","text":["Step 11 (10832) @ Episode 300/5000, loss: 821.59753418\n","Episode Reward: 38.0\n","Step 7 (11265) @ Episode 320/5000, loss: 465.133422852\n","Episode Reward: 42.0\n","Step 22 (11329) @ Episode 323/5000, loss: 352.092193604"]},{"name":"stdout","output_type":"stream","text":["Step 35 (11738) @ Episode 340/5000, loss: 786.493652344\n","Episode Reward: 14.0\n","Step 19 (12191) @ Episode 360/5000, loss: 235.880386353\n","Episode Reward: 30.0\n","Step 8 (12257) @ Episode 364/5000, loss: 462.062133789"]},{"name":"stdout","output_type":"stream","text":["Step 14 (12679) @ Episode 380/5000, loss: 750.884399414\n","Episode Reward: 35.0\n","Step 13 (13093) @ Episode 400/5000, loss: 465.013977051\n","Episode Reward: 36.0\n","Step 6 (13179) @ Episode 406/5000, loss: 582.00402832"]},{"name":"stdout","output_type":"stream","text":["Step 10 (13400) @ Episode 420/5000, loss: 211.648605347\n","Episode Reward: 39.0\n","Step 32 (13758) @ Episode 440/5000, loss: 247.730102539\n","Episode Reward: 17.0\n","Step 5 (13926) @ Episode 453/5000, loss: 119.992401123"]},{"name":"stdout","output_type":"stream","text":["Step 16 (14135) @ Episode 460/5000, loss: 250.414459229\n","Episode Reward: 33.0\n","Step 6 (14468) @ Episode 480/5000, loss: 586.940124512\n","Episode Reward: 43.0\n","Step 12 (14661) @ Episode 489/5000, loss: 474.567993164"]},{"name":"stdout","output_type":"stream","text":["Step 18 (14864) @ Episode 500/5000, loss: 102.167922974\n","Episode Reward: 31.0\n","Step 11 (15248) @ Episode 520/5000, loss: 485.934539795\n","Episode Reward: 38.0\n","Step 5 (15408) @ Episode 529/5000, loss: 433.446868896"]},{"name":"stdout","output_type":"stream","text":["Step 9 (15602) @ Episode 540/5000, loss: 476.260894775\n","Episode Reward: 40.0\n","Step 4 (15889) @ Episode 560/5000, loss: 259.433990479\n","Episode Reward: 45.0\n","Step 4 (16109) @ Episode 577/5000, loss: 0.830206513405"]},{"name":"stdout","output_type":"stream","text":["Step 21 (16170) @ Episode 580/5000, loss: 360.690612793\n","Episode Reward: 28.0\n","Step 24 (16376) @ Episode 600/5000, loss: 362.886779785\n","Episode Reward: 25.0\n","Step 36 (16673) @ Episode 620/5000, loss: 110.142845154\n","Episode Reward: 13.0\n","Step 1 (16674) @ Episode 621/5000, loss: 242.668792725"]},{"name":"stdout","output_type":"stream","text":["Step 50 (17065) @ Episode 640/5000, loss: 234.235092163\n","Episode Reward: -1.0\n","Step 9 (17370) @ Episode 660/5000, loss: 252.912094116\n","Episode Reward: 40.0\n","Step 12 (17528) @ Episode 671/5000, loss: 104.244293213"]},{"name":"stdout","output_type":"stream","text":["Step 9 (17689) @ Episode 680/5000, loss: 116.920318604\n","Episode Reward: 40.0\n","Step 9 (17964) @ Episode 700/5000, loss: 0.110034488142\n","Episode Reward: 40.0\n","Step 8 (18197) @ Episode 720/5000, loss: 0.113032907248"]},{"name":"stdout","output_type":"stream","text":["Step 43 (18232) @ Episode 720/5000, loss: 606.693969727\n","Episode Reward: 6.0\n","Step 5 (18472) @ Episode 740/5000, loss: 393.834960938\n","Episode Reward: 44.0\n","Step 7 (18710) @ Episode 760/5000, loss: 432.81149292\n","Episode Reward: 42.0\n","Step 0 (18745) @ Episode 763/5000, loss: None"]},{"name":"stdout","output_type":"stream","text":["Step 44 (19002) @ Episode 780/5000, loss: 232.872680664\n","Episode Reward: 5.0\n","Step 25 (19283) @ Episode 800/5000, loss: 492.70880127\n","Episode Reward: 24.0\n","Step 6 (19490) @ Episode 816/5000, loss: 351.277740479"]},{"name":"stdout","output_type":"stream","text":["Step 12 (19556) @ Episode 820/5000, loss: 233.703384399\n","Episode Reward: 37.0\n","Step 6 (19791) @ Episode 840/5000, loss: 230.63482666\n","Episode Reward: 43.0\n","Step 7 (20010) @ Episode 860/5000, loss: 358.634338379\n","Episode Reward: 42.0\n","Step 4 (20053) @ Episode 864/5000, loss: 338.379272461"]},{"name":"stdout","output_type":"stream","text":["Step 25 (20272) @ Episode 880/5000, loss: 123.995010376\n","Episode Reward: 24.0\n","Step 5 (20503) @ Episode 900/5000, loss: 352.164489746\n","Episode Reward: 44.0\n","Step 25 (20748) @ Episode 918/5000, loss: 466.286682129"]},{"name":"stdout","output_type":"stream","text":["Step 6 (20768) @ Episode 920/5000, loss: 106.209373474\n","Episode Reward: 43.0\n","Step 13 (21011) @ Episode 940/5000, loss: 459.95211792\n","Episode Reward: 36.0\n","Step 14 (21252) @ Episode 960/5000, loss: 0.0979721099138\n","Episode Reward: 35.0\n","Step 5 (21286) @ Episode 963/5000, loss: 370.157958984"]},{"name":"stdout","output_type":"stream","text":["Step 10 (21489) @ Episode 980/5000, loss: 131.769332886\n","Episode Reward: 39.0\n","Step 5 (21708) @ Episode 1000/5000, loss: 383.665588379\n","Episode Reward: 44.0\n","Step 2 (21960) @ Episode 1020/5000, loss: 369.267608643"]},{"name":"stdout","output_type":"stream","text":["Step 7 (21965) @ Episode 1020/5000, loss: 391.489746094\n","Episode Reward: 42.0\n","Step 5 (22152) @ Episode 1040/5000, loss: 0.0679824203253\n","Episode Reward: 44.0\n","Step 13 (22399) @ Episode 1060/5000, loss: 0.122931495309\n","Episode Reward: 36.0\n","Step 4 (22448) @ Episode 1065/5000, loss: 350.065216064"]},{"name":"stdout","output_type":"stream","text":["Step 11 (22608) @ Episode 1080/5000, loss: 241.368270874\n","Episode Reward: 38.0\n","Step 22 (22822) @ Episode 1100/5000, loss: 264.223144531\n","Episode Reward: 27.0\n","Step 8 (23067) @ Episode 1120/5000, loss: 490.317687988\n","Episode Reward: 41.0\n","Step 4 (23076) @ Episode 1122/5000, loss: 361.89755249"]},{"name":"stdout","output_type":"stream","text":["Step 13 (23286) @ Episode 1140/5000, loss: 447.694885254\n","Episode Reward: 36.0\n","Step 7 (23546) @ Episode 1160/5000, loss: 241.221389771\n","Episode Reward: 42.0\n","Step 6 (23712) @ Episode 1180/5000, loss: 343.541564941\n","Episode Reward: 43.0\n","Step 25 (23748) @ Episode 1182/5000, loss: 105.661941528"]},{"name":"stdout","output_type":"stream","text":["Step 17 (23946) @ Episode 1200/5000, loss: 324.369384766\n","Episode Reward: 32.0\n","Step 7 (24101) @ Episode 1220/5000, loss: 0.163318395615\n","Episode Reward: 42.0\n","Step 14 (24302) @ Episode 1240/5000, loss: 208.803695679\n","Episode Reward: 35.0\n","Step 6 (24359) @ Episode 1245/5000, loss: 208.552368164"]},{"name":"stdout","output_type":"stream","text":["Step 5 (24527) @ Episode 1260/5000, loss: 114.300178528\n","Episode Reward: 44.0\n","Step 9 (24713) @ Episode 1280/5000, loss: 481.541931152\n","Episode Reward: 40.0\n","Step 4 (24903) @ Episode 1300/5000, loss: 217.038665771\n","Episode Reward: 45.0\n","Step 2 (24961) @ Episode 1307/5000, loss: 454.880126953"]},{"name":"stdout","output_type":"stream","text":["Step 12 (25101) @ Episode 1320/5000, loss: 448.156677246\n","Episode Reward: 37.0\n","Step 9 (25338) @ Episode 1340/5000, loss: 198.555084229\n","Episode Reward: 40.0\n","Step 5 (25540) @ Episode 1360/5000, loss: 368.575622559\n","Episode Reward: 44.0\n","Step 1 (25573) @ Episode 1364/5000, loss: 573.571228027"]},{"name":"stdout","output_type":"stream","text":["Step 7 (25705) @ Episode 1380/5000, loss: 220.584732056\n","Episode Reward: 42.0\n","Step 12 (25864) @ Episode 1400/5000, loss: 496.753540039\n","Episode Reward: 37.0\n","Step 22 (26066) @ Episode 1420/5000, loss: 128.026428223\n","Episode Reward: 27.0\n","Step 11 (26132) @ Episode 1428/5000, loss: 108.735931396"]},{"name":"stdout","output_type":"stream","text":["Step 17 (26280) @ Episode 1440/5000, loss: 267.996276855\n","Episode Reward: 32.0\n","Step 8 (26461) @ Episode 1460/5000, loss: 602.603149414\n","Episode Reward: 41.0\n","Step 10 (26635) @ Episode 1480/5000, loss: 756.251586914\n","Episode Reward: 39.0\n","Step 2 (26709) @ Episode 1488/5000, loss: 358.278167725"]},{"name":"stdout","output_type":"stream","text":["Step 5 (26808) @ Episode 1500/5000, loss: 135.108047485\n","Episode Reward: 44.0\n","Step 11 (26979) @ Episode 1520/5000, loss: 243.611724854\n","Episode Reward: 38.0\n","Step 6 (27138) @ Episode 1540/5000, loss: 385.193206787\n","Episode Reward: 43.0\n","Step 7 (27236) @ Episode 1550/5000, loss: 358.495361328"]},{"name":"stdout","output_type":"stream","text":["Step 13 (27331) @ Episode 1560/5000, loss: 240.361846924\n","Episode Reward: 36.0\n","Step 6 (27494) @ Episode 1580/5000, loss: 463.033508301\n","Episode Reward: 43.0\n","Step 5 (27711) @ Episode 1600/5000, loss: 219.274902344\n","Episode Reward: 44.0\n","Step 4 (27772) @ Episode 1608/5000, loss: 0.16431170702"]},{"name":"stdout","output_type":"stream","text":["Step 7 (27887) @ Episode 1620/5000, loss: 217.892059326\n","Episode Reward: 42.0\n","Step 7 (28060) @ Episode 1640/5000, loss: 228.371704102\n","Episode Reward: 42.0\n","Step 10 (28219) @ Episode 1660/5000, loss: 106.645355225\n","Episode Reward: 39.0\n","Step 13 (28314) @ Episode 1669/5000, loss: 124.006690979"]},{"name":"stdout","output_type":"stream","text":["Step 9 (28409) @ Episode 1680/5000, loss: 303.574554443\n","Episode Reward: 40.0\n","Step 6 (28604) @ Episode 1700/5000, loss: 129.991668701\n","Episode Reward: 43.0\n","Step 18 (28799) @ Episode 1720/5000, loss: 244.492172241\n","Episode Reward: 31.0\n","Step 2 (28861) @ Episode 1730/5000, loss: 355.379943848"]},{"name":"stdout","output_type":"stream","text":["Step 5 (28931) @ Episode 1740/5000, loss: 210.020797729\n","Episode Reward: 44.0\n","Step 6 (29101) @ Episode 1760/5000, loss: 124.944442749\n","Episode Reward: 43.0\n","Step 6 (29275) @ Episode 1780/5000, loss: 345.663635254\n","Episode Reward: 43.0\n","Step 8 (29365) @ Episode 1794/5000, loss: 259.240234375"]},{"name":"stdout","output_type":"stream","text":["Step 6 (29413) @ Episode 1800/5000, loss: 259.120422363\n","Episode Reward: 43.0\n","Step 9 (29580) @ Episode 1820/5000, loss: 615.315673828\n","Episode Reward: 40.0\n","Step 6 (29754) @ Episode 1840/5000, loss: 365.692901611\n","Episode Reward: 43.0\n","Step 0 (29851) @ Episode 1854/5000, loss: None"]},{"name":"stdout","output_type":"stream","text":["Step 11 (29906) @ Episode 1860/5000, loss: 235.634674072\n","Episode Reward: 38.0\n","Step 14 (30081) @ Episode 1880/5000, loss: 126.996162415\n","Episode Reward: 35.0\n","Step 4 (30245) @ Episode 1900/5000, loss: 237.011734009\n","Episode Reward: 45.0\n","Step 5 (30341) @ Episode 1914/5000, loss: 111.733100891"]},{"name":"stdout","output_type":"stream","text":["Step 10 (30404) @ Episode 1920/5000, loss: 232.819015503\n","Episode Reward: 39.0\n","Step 4 (30577) @ Episode 1940/5000, loss: 251.818466187\n","Episode Reward: 45.0\n","Step 5 (30736) @ Episode 1960/5000, loss: 217.342651367\n","Episode Reward: 44.0\n","Step 2 (30836) @ Episode 1974/5000, loss: 368.863891602"]},{"name":"stdout","output_type":"stream","text":["Step 9 (30900) @ Episode 1980/5000, loss: 219.566741943\n","Episode Reward: 40.0\n","Step 4 (31064) @ Episode 2000/5000, loss: 271.852233887\n","Episode Reward: 45.0\n","Step 5 (31228) @ Episode 2020/5000, loss: 519.455810547\n","Episode Reward: 44.0\n","Step 7 (31330) @ Episode 2034/5000, loss: 111.74332428"]},{"name":"stdout","output_type":"stream","text":["Step 5 (31366) @ Episode 2040/5000, loss: 263.396118164\n","Episode Reward: 44.0\n","Step 9 (31533) @ Episode 2060/5000, loss: 372.425201416\n","Episode Reward: 40.0\n","Step 5 (31698) @ Episode 2080/5000, loss: 245.529632568\n","Episode Reward: 44.0\n","Step 9 (31802) @ Episode 2095/5000, loss: 491.498565674"]},{"name":"stdout","output_type":"stream","text":["Step 5 (31835) @ Episode 2100/5000, loss: 239.595397949\n","Episode Reward: 44.0\n","Step 6 (31990) @ Episode 2120/5000, loss: 224.22644043\n","Episode Reward: 43.0\n","Step 7 (32143) @ Episode 2140/5000, loss: 245.145248413\n","Episode Reward: 42.0\n","Step 6 (32262) @ Episode 2157/5000, loss: 123.843002319"]},{"name":"stdout","output_type":"stream","text":["Step 9 (32289) @ Episode 2160/5000, loss: 358.233215332\n","Episode Reward: 40.0\n","Step 6 (32436) @ Episode 2180/5000, loss: 131.86114502\n","Episode Reward: 43.0\n","Step 5 (32574) @ Episode 2200/5000, loss: 0.00786723941565\n","Episode Reward: 44.0\n","Step 1 (32706) @ Episode 2218/5000, loss: 111.051773071"]},{"name":"stdout","output_type":"stream","text":["Step 5 (32720) @ Episode 2220/5000, loss: 133.422332764\n","Episode Reward: 44.0\n","Step 7 (32866) @ Episode 2240/5000, loss: 105.999603271\n","Episode Reward: 42.0\n","Step 4 (33005) @ Episode 2260/5000, loss: 249.271453857\n","Episode Reward: 45.0\n","Step 8 (33140) @ Episode 2278/5000, loss: 212.385787964"]},{"name":"stdout","output_type":"stream","text":["Step 7 (33156) @ Episode 2280/5000, loss: 105.898666382\n","Episode Reward: 42.0\n","Step 6 (33308) @ Episode 2300/5000, loss: 213.972518921\n","Episode Reward: 43.0\n","Step 6 (33433) @ Episode 2320/5000, loss: 335.55947876\n","Episode Reward: 43.0\n","Step 9 (33575) @ Episode 2339/5000, loss: 484.295227051"]},{"name":"stdout","output_type":"stream","text":["Step 8 (33586) @ Episode 2340/5000, loss: 98.8156661987\n","Episode Reward: 41.0\n","Step 13 (33731) @ Episode 2360/5000, loss: 212.134338379\n","Episode Reward: 36.0\n","Step 6 (33860) @ Episode 2380/5000, loss: 265.607666016\n","Episode Reward: 43.0\n","Step 5 (33996) @ Episode 2400/5000, loss: 762.951660156\n","Episode Reward: 44.0\n","Step 2 (33998) @ Episode 2401/5000, loss: 124.738754272"]},{"name":"stdout","output_type":"stream","text":["Step 8 (34146) @ Episode 2420/5000, loss: 133.235076904\n","Episode Reward: 41.0\n","Step 6 (34288) @ Episode 2440/5000, loss: 348.202209473\n","Episode Reward: 43.0\n","Step 10 (34451) @ Episode 2460/5000, loss: 132.128112793\n","Episode Reward: 39.0\n","Step 5 (34545) @ Episode 2474/5000, loss: 111.299156189"]},{"name":"stdout","output_type":"stream","text":["Step 15 (34599) @ Episode 2480/5000, loss: 111.234764099\n","Episode Reward: 34.0\n","Step 5 (34746) @ Episode 2500/5000, loss: 0.0051719294861\n","Episode Reward: 44.0\n","Step 6 (34886) @ Episode 2520/5000, loss: 0.240382254124\n","Episode Reward: 43.0\n","Step 3 (35009) @ Episode 2536/5000, loss: 0.0308343507349"]},{"name":"stdout","output_type":"stream","text":["Step 7 (35046) @ Episode 2540/5000, loss: 462.123291016\n","Episode Reward: 42.0\n","Step 4 (35202) @ Episode 2560/5000, loss: 561.299316406\n","Episode Reward: 45.0\n","Step 8 (35344) @ Episode 2580/5000, loss: 110.238212585\n","Episode Reward: 41.0\n","Step 1 (35466) @ Episode 2600/5000, loss: 124.455032349"]},{"name":"stdout","output_type":"stream","text":["Step 4 (35469) @ Episode 2600/5000, loss: 469.414337158\n","Episode Reward: 45.0\n","Step 11 (35592) @ Episode 2620/5000, loss: 475.458679199\n","Episode Reward: 38.0\n","Step 4 (35746) @ Episode 2640/5000, loss: 110.496864319\n","Episode Reward: 45.0\n","Step 3 (35880) @ Episode 2660/5000, loss: 111.062355042"]},{"name":"stdout","output_type":"stream","text":["Step 6 (35883) @ Episode 2660/5000, loss: 245.413772583\n","Episode Reward: 43.0\n","Step 6 (36004) @ Episode 2680/5000, loss: 0.422387927771\n","Episode Reward: 43.0\n","Step 14 (36153) @ Episode 2700/5000, loss: 360.203460693\n","Episode Reward: 35.0\n","Step 18 (36294) @ Episode 2717/5000, loss: 364.443054199"]},{"name":"stdout","output_type":"stream","text":["Step 4 (36308) @ Episode 2720/5000, loss: 0.0531313978136\n","Episode Reward: 45.0\n","Step 9 (36434) @ Episode 2740/5000, loss: 125.203140259\n","Episode Reward: 40.0\n","Step 4 (36561) @ Episode 2760/5000, loss: 131.904754639\n","Episode Reward: 45.0\n","Step 5 (36709) @ Episode 2780/5000, loss: 0.00769358873367"]},{"name":"stdout","output_type":"stream","text":["Step 8 (36712) @ Episode 2780/5000, loss: 132.263092041\n","Episode Reward: 41.0\n","Step 8 (36845) @ Episode 2800/5000, loss: 124.629081726\n","Episode Reward: 41.0\n","Step 6 (36969) @ Episode 2820/5000, loss: 123.779304504\n","Episode Reward: 43.0\n","Step 5 (37104) @ Episode 2840/5000, loss: 0.0643707215786\n","Episode Reward: 44.0\n","Step 6 (37115) @ Episode 2842/5000, loss: 217.530990601"]},{"name":"stdout","output_type":"stream","text":["Step 7 (37219) @ Episode 2860/5000, loss: 0.100065395236\n","Episode Reward: 42.0\n","Step 9 (37351) @ Episode 2880/5000, loss: 0.104138880968\n","Episode Reward: 40.0\n","Step 4 (37475) @ Episode 2900/5000, loss: 215.163696289\n","Episode Reward: 45.0\n","Step 6 (37603) @ Episode 2920/5000, loss: 0.00450710486621"]},{"name":"stdout","output_type":"stream","text":["\n","Episode Reward: 43.0\n","Step 4 (37732) @ Episode 2940/5000, loss: 0.038909368217\n","Episode Reward: 45.0\n","Step 7 (37858) @ Episode 2960/5000, loss: 0.0544732287526\n","Episode Reward: 42.0\n","Step 6 (37984) @ Episode 2980/5000, loss: 219.53604126\n","Episode Reward: 43.0\n","Step 2 (38073) @ Episode 2993/5000, loss: 127.341072083"]},{"name":"stdout","output_type":"stream","text":["Step 4 (38118) @ Episode 3000/5000, loss: 110.550323486\n","Episode Reward: 45.0\n","Step 9 (38233) @ Episode 3020/5000, loss: 0.0146706104279\n","Episode Reward: 40.0\n","Step 5 (38356) @ Episode 3040/5000, loss: 109.625762939\n","Episode Reward: 44.0\n","Step 4 (38495) @ Episode 3060/5000, loss: 109.611251831\n","Episode Reward: 45.0\n","Step 1 (38501) @ Episode 3062/5000, loss: 0.0508892163634"]},{"name":"stdout","output_type":"stream","text":["Step 6 (38616) @ Episode 3080/5000, loss: 0.0418089739978\n","Episode Reward: 43.0\n","Step 5 (38759) @ Episode 3100/5000, loss: 243.630477905\n","Episode Reward: 44.0\n","Step 6 (38881) @ Episode 3120/5000, loss: 110.918998718\n","Episode Reward: 43.0\n","Step 4 (38986) @ Episode 3140/5000, loss: 355.061157227\n","Episode Reward: 45.0\n","Step 6 (38996) @ Episode 3142/5000, loss: 0.0740653276443"]},{"name":"stdout","output_type":"stream","text":["Step 6 (39101) @ Episode 3160/5000, loss: 109.259727478\n","Episode Reward: 43.0\n","Step 4 (39217) @ Episode 3180/5000, loss: 125.538909912\n","Episode Reward: 45.0\n","Step 6 (39333) @ Episode 3200/5000, loss: 0.0162459332496\n","Episode Reward: 43.0\n","Step 6 (39467) @ Episode 3220/5000, loss: 109.487319946\n","Episode Reward: 43.0\n","Step 5 (39472) @ Episode 3221/5000, loss: 0.00912380870432"]},{"name":"stdout","output_type":"stream","text":["Step 7 (39591) @ Episode 3240/5000, loss: 126.132339478\n","Episode Reward: 42.0\n","Step 6 (39709) @ Episode 3260/5000, loss: 111.402412415\n","Episode Reward: 43.0\n","Step 6 (39820) @ Episode 3280/5000, loss: 0.0235657766461\n","Episode Reward: 43.0\n","Step 4 (39927) @ Episode 3300/5000, loss: 0.0498711057007\n","Episode Reward: 45.0\n","Step 5 (39949) @ Episode 3305/5000, loss: 230.679718018"]},{"name":"stdout","output_type":"stream","text":["Step 4 (40037) @ Episode 3320/5000, loss: 0.0829026997089\n","Episode Reward: 45.0\n","Step 6 (40141) @ Episode 3340/5000, loss: 256.066894531\n","Episode Reward: 43.0\n","Step 4 (40251) @ Episode 3360/5000, loss: 0.00732845626771\n","Episode Reward: 45.0\n","Step 7 (40375) @ Episode 3380/5000, loss: 109.409614563\n","Episode Reward: 42.0\n","Step 4 (40393) @ Episode 3383/5000, loss: 140.282470703"]},{"name":"stdout","output_type":"stream","text":["Step 4 (40490) @ Episode 3400/5000, loss: 0.00906412955374\n","Episode Reward: 45.0\n","Step 4 (40601) @ Episode 3420/5000, loss: 110.130973816\n","Episode Reward: 45.0\n","Step 8 (40712) @ Episode 3440/5000, loss: 110.135787964\n","Episode Reward: 41.0\n","Step 4 (40825) @ Episode 3460/5000, loss: 239.025146484\n","Episode Reward: 45.0\n","Step 3 (40846) @ Episode 3465/5000, loss: 135.304748535"]},{"name":"stdout","output_type":"stream","text":["Step 8 (40944) @ Episode 3480/5000, loss: 127.736160278\n","Episode Reward: 41.0\n","Step 6 (41055) @ Episode 3500/5000, loss: 111.288604736\n","Episode Reward: 43.0\n","Step 5 (41159) @ Episode 3520/5000, loss: 111.159645081\n","Episode Reward: 44.0\n","Step 7 (41263) @ Episode 3540/5000, loss: 234.621398926\n","Episode Reward: 42.0\n","Step 6 (41297) @ Episode 3546/5000, loss: 234.394836426"]},{"name":"stdout","output_type":"stream","text":["Step 8 (41386) @ Episode 3560/5000, loss: 125.526359558\n","Episode Reward: 41.0\n","Step 4 (41512) @ Episode 3580/5000, loss: 220.840393066\n","Episode Reward: 45.0\n","Step 8 (41640) @ Episode 3600/5000, loss: 0.0238254219294\n","Episode Reward: 41.0\n","Step 7 (41762) @ Episode 3620/5000, loss: 132.534957886\n","Episode Reward: 42.0\n","Step 6 (41768) @ Episode 3621/5000, loss: 254.981903076"]},{"name":"stdout","output_type":"stream","text":["Step 5 (41878) @ Episode 3640/5000, loss: 216.575271606\n","Episode Reward: 44.0\n","Step 4 (41991) @ Episode 3660/5000, loss: 0.00522891711444\n","Episode Reward: 45.0\n","Step 4 (42099) @ Episode 3680/5000, loss: 217.636444092\n","Episode Reward: 45.0\n","Step 4 (42201) @ Episode 3700/5000, loss: 132.652069092\n","Episode Reward: 45.0\n","Step 4 (42229) @ Episode 3706/5000, loss: 124.564620972"]},{"name":"stdout","output_type":"stream","text":["Step 4 (42302) @ Episode 3720/5000, loss: 0.177671164274\n","Episode Reward: 45.0\n","Step 4 (42400) @ Episode 3740/5000, loss: 241.124145508\n","Episode Reward: 45.0\n","Step 4 (42524) @ Episode 3760/5000, loss: 102.873603821\n","Episode Reward: 45.0\n","Step 5 (42632) @ Episode 3780/5000, loss: 0.00374609185383\n","Episode Reward: 44.0\n","Step 0 (42659) @ Episode 3786/5000, loss: None"]},{"name":"stdout","output_type":"stream","text":["Step 6 (42750) @ Episode 3800/5000, loss: 132.576751709\n","Episode Reward: 43.0\n","Step 4 (42859) @ Episode 3820/5000, loss: 131.195999146\n","Episode Reward: 45.0\n","Step 5 (42973) @ Episode 3840/5000, loss: 123.415466309\n","Episode Reward: 44.0\n","Step 4 (43077) @ Episode 3860/5000, loss: 124.854614258\n","Episode Reward: 45.0\n","Step 5 (43106) @ Episode 3867/5000, loss: 124.06703949"]},{"name":"stdout","output_type":"stream","text":["Step 7 (43176) @ Episode 3880/5000, loss: 0.0314719714224\n","Episode Reward: 42.0\n","Step 4 (43286) @ Episode 3900/5000, loss: 0.00629771593958\n","Episode Reward: 45.0\n","Step 4 (43393) @ Episode 3920/5000, loss: 0.0660840421915\n","Episode Reward: 45.0\n","Step 6 (43512) @ Episode 3940/5000, loss: 0.328566789627\n","Episode Reward: 43.0\n","Step 4 (43534) @ Episode 3944/5000, loss: 135.320144653"]},{"name":"stdout","output_type":"stream","text":["Step 6 (43633) @ Episode 3960/5000, loss: 135.658508301\n","Episode Reward: 43.0\n","Step 5 (43745) @ Episode 3980/5000, loss: 350.552490234\n","Episode Reward: 44.0\n","Step 4 (43849) @ Episode 4000/5000, loss: 321.348449707\n","Episode Reward: 45.0\n","Step 8 (43958) @ Episode 4020/5000, loss: 107.18421936\n","Episode Reward: 41.0\n","Step 5 (43989) @ Episode 4025/5000, loss: 340.51739502"]},{"name":"stdout","output_type":"stream","text":["Step 4 (44062) @ Episode 4040/5000, loss: 259.151519775\n","Episode Reward: 45.0\n","Step 5 (44163) @ Episode 4060/5000, loss: 0.0623681098223\n","Episode Reward: 44.0\n","Step 6 (44281) @ Episode 4080/5000, loss: 0.0137936603278\n","Episode Reward: 43.0\n","Step 10 (44385) @ Episode 4100/5000, loss: 262.835723877\n","Episode Reward: 39.0\n","Step 1 (44415) @ Episode 4107/5000, loss: 122.139839172"]},{"name":"stdout","output_type":"stream","text":["Step 4 (44487) @ Episode 4120/5000, loss: 263.141723633\n","Episode Reward: 45.0\n","Step 5 (44594) @ Episode 4140/5000, loss: 123.828674316\n","Episode Reward: 44.0\n","Step 4 (44692) @ Episode 4160/5000, loss: 219.730834961\n","Episode Reward: 45.0\n","Step 5 (44795) @ Episode 4180/5000, loss: 0.0655496418476\n","Episode Reward: 44.0\n","Step 2 (44836) @ Episode 4189/5000, loss: 231.477172852"]},{"name":"stdout","output_type":"stream","text":["Step 4 (44908) @ Episode 4200/5000, loss: 239.147628784\n","Episode Reward: 45.0\n","Step 4 (45011) @ Episode 4220/5000, loss: 0.00788408517838\n","Episode Reward: 45.0\n","Step 4 (45119) @ Episode 4240/5000, loss: 0.183668926358\n","Episode Reward: 45.0\n","Step 4 (45232) @ Episode 4260/5000, loss: 132.277175903\n","Episode Reward: 45.0\n","Step 0 (45260) @ Episode 4267/5000, loss: None"]},{"name":"stdout","output_type":"stream","text":["Step 4 (45332) @ Episode 4280/5000, loss: 110.876396179\n","Episode Reward: 45.0\n","Step 4 (45420) @ Episode 4300/5000, loss: 128.482666016\n","Episode Reward: 45.0\n","Step 4 (45506) @ Episode 4320/5000, loss: 113.283210754\n","Episode Reward: 45.0\n","Step 4 (45609) @ Episode 4340/5000, loss: 113.561187744\n","Episode Reward: 45.0\n","Step 3 (45663) @ Episode 4350/5000, loss: 250.512908936"]},{"name":"stdout","output_type":"stream","text":["Step 4 (45716) @ Episode 4360/5000, loss: 0.137632265687\n","Episode Reward: 45.0\n","Step 8 (45821) @ Episode 4380/5000, loss: 128.818115234\n","Episode Reward: 41.0\n","Step 4 (45925) @ Episode 4400/5000, loss: 112.927612305\n","Episode Reward: 45.0\n","Step 4 (46032) @ Episode 4420/5000, loss: 110.687316895\n","Episode Reward: 45.0\n","Step 2 (46069) @ Episode 4429/5000, loss: 0.156630903482"]},{"name":"stdout","output_type":"stream","text":["Step 9 (46131) @ Episode 4440/5000, loss: 0.0776492655277\n","Episode Reward: 40.0\n","Step 6 (46231) @ Episode 4460/5000, loss: 0.00790701713413\n","Episode Reward: 43.0\n","Step 7 (46339) @ Episode 4480/5000, loss: 0.132820948958\n","Episode Reward: 42.0\n","Step 10 (46448) @ Episode 4500/5000, loss: 111.841567993\n","Episode Reward: 39.0\n","Step 0 (46479) @ Episode 4507/5000, loss: None"]},{"name":"stdout","output_type":"stream","text":["Step 5 (46549) @ Episode 4520/5000, loss: 133.01890564\n","Episode Reward: 44.0\n","Step 5 (46642) @ Episode 4540/5000, loss: 0.00339878560044\n","Episode Reward: 44.0\n","Step 4 (46743) @ Episode 4560/5000, loss: 0.00613372819498\n","Episode Reward: 45.0\n","Step 4 (46845) @ Episode 4580/5000, loss: 111.258331299\n","Episode Reward: 45.0\n","Step 1 (46889) @ Episode 4588/5000, loss: 111.321266174"]},{"name":"stdout","output_type":"stream","text":["Step 4 (46948) @ Episode 4600/5000, loss: 111.299888611\n","Episode Reward: 45.0\n","Step 4 (47042) @ Episode 4620/5000, loss: 0.00633367151022\n","Episode Reward: 45.0\n","Step 4 (47133) @ Episode 4640/5000, loss: 0.0648730546236\n","Episode Reward: 45.0\n","Step 4 (47228) @ Episode 4660/5000, loss: 0.00516100600362\n","Episode Reward: 45.0\n","Step 0 (47280) @ Episode 4671/5000, loss: None"]},{"name":"stdout","output_type":"stream","text":["Step 5 (47333) @ Episode 4680/5000, loss: 100.846092224\n","Episode Reward: 44.0\n","Step 4 (47432) @ Episode 4700/5000, loss: 247.630340576\n","Episode Reward: 45.0\n","Step 4 (47526) @ Episode 4720/5000, loss: 0.0456026494503\n","Episode Reward: 45.0\n","Step 4 (47622) @ Episode 4740/5000, loss: 0.0133384084329\n","Episode Reward: 45.0\n","Step 3 (47673) @ Episode 4752/5000, loss: 0.00928094796836"]},{"name":"stdout","output_type":"stream","text":["Step 4 (47711) @ Episode 4760/5000, loss: 0.31518805027\n","Episode Reward: 45.0\n","Step 4 (47804) @ Episode 4780/5000, loss: 0.0756176710129\n","Episode Reward: 45.0\n","Step 4 (47900) @ Episode 4800/5000, loss: 0.00148229347542\n","Episode Reward: 45.0\n","Step 4 (47988) @ Episode 4820/5000, loss: 0.0017830231227\n","Episode Reward: 45.0\n","Step 1 (48045) @ Episode 4833/5000, loss: 124.232177734"]},{"name":"stdout","output_type":"stream","text":["Step 4 (48080) @ Episode 4840/5000, loss: 0.0797159895301\n","Episode Reward: 45.0\n","Step 5 (48172) @ Episode 4860/5000, loss: 0.00476320274174\n","Episode Reward: 44.0\n","Step 5 (48268) @ Episode 4880/5000, loss: 107.88760376\n","Episode Reward: 44.0\n","Step 4 (48359) @ Episode 4900/5000, loss: 108.477928162\n","Episode Reward: 45.0\n","Step 0 (48415) @ Episode 4912/5000, loss: None"]},{"name":"stdout","output_type":"stream","text":["Step 6 (48458) @ Episode 4920/5000, loss: 133.048873901\n","Episode Reward: 43.0\n","Step 4 (48559) @ Episode 4940/5000, loss: 0.190180391073\n","Episode Reward: 45.0\n","Step 6 (48649) @ Episode 4960/5000, loss: 0.0223834626377\n","Episode Reward: 43.0\n","Step 6 (48746) @ Episode 4980/5000, loss: 0.0118256341666\n","Episode Reward: 43.0\n","Step 3 (48798) @ Episode 4992/5000, loss: 124.840713501"]},{"name":"stdout","output_type":"stream","text":["Step 5 (48835) @ Episode 5000/5000, loss: 131.480865479\n","Episode Reward: 44.0\n","Elasped: 0:27:09.397037.\n"]}],"source":["tf.reset_default_graph()\n","\n","# Where we save our checkpoints and graphs\n","experiment_dir = os.path.abspath(\"./experiments/{}\".format(type(env).__name__))\n","\n","# Create a glboal step variable\n","global_step = tf.Variable(0, name='global_step', trainable=False)\n","    \n","# Create estimators\n","q_estimator = Estimator(scope=\"q\", summaries_dir=experiment_dir)\n","target_estimator = Estimator(scope=\"target_q\")\n","\n","# State processor\n","state_processor = StateProcessor()\n","\n","start_time = datetime.datetime.now()\n","# Run it!\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    for t, stats in deep_q_learning(sess,\n","                                    env,\n","                                    q_estimator=q_estimator,\n","                                    target_estimator=target_estimator,\n","                                    state_processor=state_processor,\n","                                    experiment_dir=experiment_dir,\n","                                    num_episodes=5000,  # 5000\n","                                    replay_memory_size=500,  # 50000\n","                                    replay_memory_init_size=5000,  # 5000\n","                                    update_target_estimator_every=250,  # 1000\n","                                    epsilon_start=1.0,\n","                                    epsilon_end=0.1,\n","                                    epsilon_decay_steps=50000,\n","                                    discount_factor=0.99,\n","                                    batch_size=BATCH_SIZE,\n","                                    restore=False):\n","        if len(stats.episode_rewards) % 20 == 0:\n","            print(\"\\nEpisode Reward: {}\".format(stats.episode_rewards[-1]))\n","\n","\n","elapsed = datetime.datetime.now() - start_time\n","print(\"Elasped: {}.\".format(elapsed))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":547},"colab_type":"code","executionInfo":{"elapsed":1223,"status":"ok","timestamp":1523636814930,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"PZ9yE9UtF5ov","outputId":"c2d80ff4-63e7-476e-812e-bd5b00a442b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode rewards:\n"]},{"data":{"image/png":"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","text/plain":["<matplotlib.figure.Figure at 0x7f33744d7d10>"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Episode lengths:\n"]},{"data":{"image/png":"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","text/plain":["<matplotlib.figure.Figure at 0x7f33739d5110>"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["print(\"Episode rewards:\")\n","plt.plot(stats.episode_rewards)\n","plt.show()\n","print(\"Episode lengths:\")\n","plt.plot(stats.episode_lengths)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","id":"QW_fYF9PF5o0"},"outputs":[],"source":["import pickle\n","\n","pickle.dump(stats, open(experiment_dir + \"/stats.p\", \"wb\" ))\n","\n","# st = pickle.load(open(experiment_dir + \"/stats.p\", \"rb\" ))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":681,"status":"ok","timestamp":1523632726580,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"8bjHz8LCVJn9","outputId":"6a2352e1-46ae-4f2f-f636-1d4adc810374"},"outputs":[{"data":{"text/plain":["'/device:GPU:0'"]},"execution_count":17,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["tf.test.gpu_device_name()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":3264,"status":"ok","timestamp":1523634260062,"user":{"displayName":"Karol Kubicki","photoUrl":"//lh5.googleusercontent.com/-XiBXg4xPKn0/AAAAAAAAAAI/AAAAAAAABbU/GxyCeqXniQM/s50-c-k-no/photo.jpg","userId":"114900524903672171380"},"user_tz":-60},"id":"Tomw3MkeraR_","outputId":"e08c1896-dd22-4c2f-8a50-726dd9b02b92"},"outputs":[{"data":{"text/plain":["'1.6.0'"]},"execution_count":38,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["tf.__version__"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"default_view":{},"name":"DQN in side effects sokoban.ipynb","provenance":[{"file_id":"1sU2HKqZwzmamFfkMkpxSA3X5JgPzsI5U","timestamp":1523638775840}],"version":"0.3.2","views":{}},"kernelspec":{"display_name":"rl_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}
