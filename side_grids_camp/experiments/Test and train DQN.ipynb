{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from collections import deque, namedtuple\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\")\n",
    "\n",
    "from side_grids_camp.agents.dqn import StateProcessor, Estimator, DQNAgent\n",
    "from ai_safety_gridworlds.environments.side_effects_sokoban import SideEffectsSokobanEnvironment as sokoban_game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/langust/progz/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sokoban in grey-scale:\n",
      "[[152 152 152 152 152 152]\n",
      " [152 219 134 152 152 152]\n",
      " [152 219  78 219 219 152]\n",
      " [152 152 219 219 219 152]\n",
      " [152 152 152 219 129 152]\n",
      " [152 152 152 152 152 152]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA3RJREFUeJzt2rFt40AURdHVgo0oZU9K1QMrmCJU7DgmFBgO6DGuzokHxEsufsLbnPMf0PR/9QDgOgKHMIFDmMAhTOAQJnAIEziECRzCBA5h2xUfHWP4PQ4udhzH7bs3LjiECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmHb6gG/4TiO1RPePJ/P1RNO7vf76glcwAWHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BC2rR7wqV6v1+oJJ3PO1RP+vDHG6gk/5oJDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BC2rR7wG8YYqye8mXOunsAHcMEhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAjbVg/4VGOM1RNOjuNYPeHk8XisnvBm3/fVE37MBYcwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgELatHsDfMMZYPeFk3/fVExJccAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwm5zztUbgIu44BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUPYFxJaIJpC2XzHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05593616  0.08785374  0.01562183 -0.        ]\n",
      " [ 0.05593616  0.08785374  0.01562183 -0.        ]\n",
      " [ 0.05593616  0.08785374  0.01562183 -0.        ]\n",
      " [ 0.05593616  0.08785374  0.01562183 -0.        ]\n",
      " [ 0.05593616  0.08785374  0.01562183 -0.        ]\n",
      " [ 0.05593616  0.08785374  0.01562183 -0.        ]\n",
      " [ 0.05593615  0.08785375  0.01562183 -0.        ]\n",
      " [ 0.05593615  0.08785375  0.01562183 -0.        ]]\n",
      "[ 0.08785374  0.08785374  0.08785374  0.08785374  0.08785374  0.08785374\n",
      "  0.08785375  0.08785375]\n",
      "57.1253\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Test preprocessing and estimator\n",
    "#\n",
    "\n",
    "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "\n",
    "env = sokoban_game(level=0)\n",
    "actions_num = env.action_spec().maximum + 1\n",
    "world_shape = env.observation_spec()['board'].shape\n",
    "frames_state = 2\n",
    "batch_size = 8\n",
    "e = Estimator(actions_num, world_shape[0], world_shape[1], scope=\"test\")\n",
    "sp = StateProcessor(world_shape[0], world_shape[1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Example observation batch\n",
    "    time_step = env.reset()\n",
    "    \n",
    "    frame = np.moveaxis(time_step.observation['RGB'], 0, -1)\n",
    "    observation_p = sp.process(sess, frame)\n",
    "\n",
    "    print(\"Sokoban in grey-scale:\")\n",
    "    print(observation_p)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(observation_p/255.0, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    observation = np.stack([observation_p] * frames_state, axis=2)\n",
    "    observations = np.array([observation] * batch_size)\n",
    "    \n",
    "    # Test Prediction\n",
    "    pred = e.predict(sess, observations)\n",
    "    print(pred)\n",
    "    print(pred.max(axis=1))\n",
    "\n",
    "    # Test training step\n",
    "    y = np.array([10.0, 4.0] * (batch_size/2))\n",
    "    a = np.array([1, 3] * (batch_size/2))\n",
    "    print(e.update(sess, observations, a, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some tests:\n",
    "\n",
    "# TimeStep inherits from:\n",
    "#   collections.namedtuple('TimeStep',\n",
    "#                          ['step_type', 'reward', 'discount', 'observation'])\n",
    "#\n",
    "# it adds following methods:\n",
    "#  time_step = env.reset()\n",
    "#  time_step.first()\n",
    "#  time_step.mid()\n",
    "#  time_step.last()\n",
    "\n",
    "time_step = env.reset()\n",
    "print(\"Step type: first {}, mid {}, last {}\".format(time_step.first(), time_step.mid(), time_step.last()))\n",
    "print(\"Reward {}, discount {}\".format(time_step.reward, time_step.discount))\n",
    "print(\"Observation type: {}\".format(type(time_step.observation)))\n",
    "\n",
    "print(\"Let's act..\")\n",
    "time_step = env.step(2)\n",
    "print(\"Step type: first {}, mid {}, last {}\".format(time_step.first(), time_step.mid(), time_step.last()))\n",
    "print(\"Reward {}, discount {}\".format(time_step.reward, time_step.discount))\n",
    "print(\"Observation type: {}\".format(type(time_step.observation)))\n",
    "\n",
    "print(\"RGB image dims: {}\".format(time_step.observation['RGB'].shape))\n",
    "print(\"Plot from rgb:\")\n",
    "frame = np.moveaxis(time_step.observation['RGB'],0,-1)\n",
    "plt.figure()\n",
    "plt.imshow(frame)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plot board:\")\n",
    "plt.figure()\n",
    "plt.imshow(time_step.observation['board'])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EpisodeStats = namedtuple(\"EpisodeStats\", [\"episode_lengths\", \"episode_rewards\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Start training side effects sokoban.\")\n",
    "env = sokoban_game(level=0)\n",
    "actions_num = env.action_spec().maximum + 1\n",
    "world_shape = env.observation_spec()['board'].shape\n",
    "frames_state = 2\n",
    "batch_size = 32\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "num_episodes = 50  # 5000\n",
    "stats = EpisodeStats(episode_lengths=np.zeros(num_episodes),\n",
    "                     episode_rewards=np.zeros(num_episodes))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    agent = DQNAgent(sess,\n",
    "                 world_shape,\n",
    "                 actions_num,\n",
    "                 env,\n",
    "                 frames_state=frames_state,\n",
    "                 experiment_dir=None,\n",
    "                 replay_memory_size=10000,  # 10000\n",
    "                 replay_memory_init_size=500,  # 3000\n",
    "                 update_target_estimator_every=250,  # 500\n",
    "                 discount_factor=0.99,\n",
    "                 epsilon_start=1.0,\n",
    "                 epsilon_end=0.1,\n",
    "                 epsilon_decay_steps=50000,\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "\n",
    "        # Save the current checkpoint\n",
    "        agent.save()\n",
    "\n",
    "        ret = 0\n",
    "        time_step = env.reset()  # for the description of timestep see ai_safety_gridworlds.environments.shared.rl.environment\n",
    "        for t in itertools.count():\n",
    "            action = agent.act(time_step.observation)\n",
    "            time_step = env.step(action)\n",
    "            loss = agent.learn(time_step, action)\n",
    "\n",
    "            print(\"\\rStep {} ({}) @ Episode {}/{}, loss: {}\".format(\n",
    "                        t, agent.total_t, i_episode + 1, num_episodes, loss), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            ret += time_step.reward\n",
    "            if time_step.last():\n",
    "                break\n",
    "        stats.episode_lengths[i_episode] = t\n",
    "        stats.episode_rewards[i_episode] = ret\n",
    "        if i_episode % 25 == 0:\n",
    "            print(\"\\nEpisode return: {}, and performance: {}.\".format(ret, env.get_last_performance()))\n",
    "\n",
    "\n",
    "elapsed = datetime.datetime.now() - start_time\n",
    "print(\"Return: {}, elasped: {}.\".format(ret, elapsed))\n",
    "print(\"Traning finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py27)",
   "language": "python",
   "name": "conda_py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
